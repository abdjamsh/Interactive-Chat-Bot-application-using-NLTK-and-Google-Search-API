{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "QiS3OuiTX3lb",
    "outputId": "93d3ea2a-0a30-461d-c490-111a36b978dd"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import random\n",
    "import string # to process standard python strings\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('punkt') # first-time use only\n",
    "#nltk.download('wordnet') # first-time use only\n",
    "#nltk.download('popular', quiet=True)\n",
    "import openpyxl\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zC8yoTHwZ715"
   },
   "outputs": [],
   "source": [
    "from googlesearch import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "5t2j4P1LYQyq",
    "outputId": "8d466e30-749d-4bd0-bb8b-e7d3cf7f4e3c"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8cEEfSOKBiW0"
   },
   "outputs": [],
   "source": [
    "# Keyword Matching\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",\"yo \")\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "\n",
    "def greeting(sentence):\n",
    "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MIAoE-0TPBs9"
   },
   "outputs": [],
   "source": [
    "#Preprocessing Lemmatization\n",
    "lemmer = WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-n3nf2QC22wI"
   },
   "outputs": [],
   "source": [
    "def response(url,query):\n",
    "  \n",
    "\n",
    "  headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36'}\n",
    "  reg_url = url[0]\n",
    "  req = urllib.request.Request(url=reg_url, headers=headers)\n",
    "  \n",
    "    \n",
    "  out1=\"\"\n",
    "  html = urllib.request.urlopen(req).read()\n",
    "  soup = BeautifulSoup(html, 'html.parser')\n",
    "  paragraphs=soup.find_all('p')\n",
    "  for para in paragraphs:\n",
    "    data=para.get_text()\n",
    "    data=re.sub(r'(\\(adsbygo.*)',\"\",data)\n",
    "    data=re.sub(r'[\\n\\t]',\"\",data)\n",
    "    out1 = out1+data\n",
    "  with open(\"data_set1.txt\",'a',encoding='utf8') as file1:\n",
    "    file1.write(out1)\n",
    "    \n",
    "  reg_url = url[1]\n",
    "  req = urllib.request.Request(url=reg_url, headers=headers)  \n",
    "\n",
    "  out2 = \"\"\n",
    "  html = urllib.request.urlopen(req).read()\n",
    "  soup = BeautifulSoup(html, 'html.parser')\n",
    "  paragraphs=soup.find_all('p')\n",
    "  for para in paragraphs:\n",
    "    data=para.get_text()\n",
    "    data=re.sub(r'(\\(adsbygo.*)',\"\",data)\n",
    "    data=re.sub(r'[\\n\\t]',\"\",data)\n",
    "    out2 = out2+data\n",
    "  with open(\"data_set2.txt\",'a',encoding='utf8') as file1:\n",
    "    file1.write(out2)\n",
    "  \n",
    "  reg_url = url[2]\n",
    "  req = urllib.request.Request(url=reg_url, headers=headers)\n",
    "\n",
    "  out3 = \"\"\n",
    "  html = urllib.request.urlopen(req).read()\n",
    "  soup = BeautifulSoup(html, 'html.parser')\n",
    "  paragraphs=soup.find_all('p')\n",
    "  for para in paragraphs:\n",
    "    data=para.get_text()\n",
    "    data=re.sub(r'(\\(adsbygo.*)',\"\",data)\n",
    "    data=re.sub(r'[\\n\\t]',\"\",data)\n",
    "    out3 = out3+data\n",
    "  with open(\"data_set3.txt\",'a',encoding='utf8') as file1:\n",
    "    file1.write(out3)\n",
    "\n",
    "  return tfidf(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0niFLkiLodX"
   },
   "outputs": [],
   "source": [
    "def tfidf(query):\n",
    "\n",
    "  robo_response=''\n",
    "\n",
    "  a1=open('data_set1.txt','r',errors = 'ignore')\n",
    "  val1=a1.read()\n",
    "  val1=val1.lower()# converts to lowercase\n",
    "  sent_tokens_val1 = nltk.sent_tokenize(val1)# converts to list of sentences \n",
    "  word_tokens_val1 = nltk.word_tokenize(val1)\n",
    "\n",
    "  a2=open('data_set2.txt','r',errors = 'ignore')\n",
    "  val2=a2.read()\n",
    "  val2=val2.lower()# converts to lowercase\n",
    "  sent_tokens_val2 = nltk.sent_tokenize(val2)# converts to list of sentences \n",
    "  word_tokens_val2 = nltk.word_tokenize(val2)\n",
    "\n",
    "  a3=open('data_set3.txt','r',errors = 'ignore')\n",
    "  val3=a3.read()\n",
    "  val3=val3.lower()# converts to lowercase\n",
    "  sent_tokens_val3 = nltk.sent_tokenize(val3)# converts to list of sentences \n",
    "  word_tokens_val3 = nltk.word_tokenize(val3)\n",
    "\n",
    "  sent_tokens_val1.append(query)\n",
    "  sent_tokens_val2.append(query)\n",
    "  sent_tokens_val3.append(query)\n",
    "\n",
    "  TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "\n",
    "  req_tfidf = []\n",
    "\n",
    "  tfidf1 = TfidfVec.fit_transform(sent_tokens_val1)\n",
    "  vals1 = cosine_similarity(tfidf1[-1], tfidf1)\n",
    "  idx1=vals1.argsort()[0][-2]\n",
    "  flat1 = vals1.flatten()\n",
    "  flat1.sort()\n",
    "  req_tfidf.append(flat1[-2])\n",
    "\n",
    "  tfidf2 = TfidfVec.fit_transform(sent_tokens_val2)\n",
    "  vals2 = cosine_similarity(tfidf2[-1], tfidf2)\n",
    "  idx2=vals2.argsort()[0][-2]\n",
    "  flat2 = vals2.flatten()\n",
    "  flat2.sort()\n",
    "  req_tfidf.append(flat2[-2])\n",
    "\n",
    "  tfidf3 = TfidfVec.fit_transform(sent_tokens_val3)\n",
    "  vals3 = cosine_similarity(tfidf3[-1], tfidf3)\n",
    "  idx3=vals3.argsort()[0][-2]\n",
    "  flat3 = vals3.flatten()\n",
    "  flat3.sort()\n",
    "  req_tfidf.append(flat3[-2])\n",
    "\n",
    "  max_req_tfidf = max(req_tfidf)\n",
    "  index = req_tfidf.index(max(req_tfidf))\n",
    "\n",
    "  if index == 0:\n",
    "    sent_tokens = sent_tokens_val1\n",
    "    idx = idx1\n",
    "  elif index == 1:\n",
    "    sent_tokens = sent_tokens_val2\n",
    "    idx = idx2\n",
    "  elif index == 2:\n",
    "    sent_tokens = sent_tokens_val3\n",
    "    idx = idx3\n",
    "  \n",
    "  if(max_req_tfidf==0):\n",
    "    robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
    "    return robo_response\n",
    "  else:\n",
    "    robo_response = robo_response+sent_tokens[idx]\n",
    "    return robo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WRKiHASAZwI7"
   },
   "outputs": [],
   "source": [
    "def google(query):\n",
    "  url = []\n",
    "  for j in search(query, tld=\"com\", num=3, stop=3, pause=5):\n",
    "    url.append(j)\n",
    "  return response(url,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "SBkn7IsRYmRz",
    "outputId": "816c080f-fd9a-4252-f802-200982407e6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRO: My name is BRO. I will answer your queries about Computers and AI. If you want to exit, type Bye!\n",
      "what is macchine learning\n",
      "BRO: so the purpose of reinforcement learning is to learn the best plan.there are many reinforcement learning algorithms are present in machine learning, which applied for different reinforcement learning applications.\n",
      "what is machine learning\n",
      "BRO: and now machine learning is present in so many segments of technology, that we donâ€™t even realise it while using it.machine learning mainly divided into three categories, which are as follows-supervised learning is the first type of machine learning, in which labelled data used to train the algorithms.\n",
      "who is mahatma gandhi\n",
      "BRO: these experiments took flak from most of the indian politicians and the people of india.favourite thingsfavourite personsgautama buddha, harishchandra, and his mother putlibai favourite authorleo tolstoy girls, affairs and moremarital statusmarriedaffairs/girlfriendsnot knownwifekasturba gandhichildrensons-harilalmanilalramdasdevdasdaughters- n/amahatma gandhi in his childhoodmahatma gandhi in his childhoodyoung mahatma gandhiyoung mahatma gandhimahatma gandhi (seated extreme right) with the members of vegetarian societymahatma gandhi (seated extreme right) with the members of vegetarian societymahatma gandhi in londonmahatma gandhi in londonmahatma gandhi pietermaritzburg stationmahatma gandhi pietermaritzburg stationmahatma gandhi with the founders of natal indian congressmahatma gandhi with the founders of natal indian congressmahatma gandhi ambulance corpsmahatma gandhi ambulance corpsmahatma gandhi first satyagraha in south africamahatma gandhi first satyagraha in south africamahatma gandhi and leo tolstoymahatma gandhi and leo tolstoymahatma gandhi book hind swarajmahatma gandhi book hind swarajmahatma gandhi tolstoy farmmahatma gandhi tolstoy farmmahatma gandhi with gopal krishna gokhalemahatma gandhi with gopal krishna gokhalemahatma gandhi satyagraha ashram at kochrabmahatma gandhi satyagraha ashram at kochrabyoung india first issue under the editorship of mahatma gandhiyoung india first issue under the editorship of mahatma gandhia news about mahatma gandhi in yarwada jaila news about mahatma gandhi in yarwada jailmahatma gandhi 21-day fastmahatma gandhi 21-day fastmahatma gandhi presiding belgaum congress sessionmahatma gandhi presiding belgaum congress sessionmahatma gandhi at the lahore sessionmahatma gandhi at the lahore sessionmahatma gandhi time magazinemahatma gandhi time magazinemahatma gandhi with jawaharlal nehrumahatma gandhi with jawaharlal nehrukasturba gandhi deathkasturba gandhi deathmahatma gandhi and nobel prizemahatma gandhi and nobel prizegeir lundestadgeir lundestadmahatma gandhi with rabindranath tagoremahatma gandhi with rabindranath tagoremahatma gandhi soviet union stampmahatma gandhi soviet union stampmartin luther king standing in front of a portrait of mahatma gandhimartin luther king standing in front of a portrait of mahatma gandhinelson mandela giving a memento to k r narayanannelson mandela giving a memento to k r narayananmahatma life of gandhi, 1869â€“1948mahatma life of gandhi, 1869â€“1948ram rajya 1943ram rajya 1943gandhi series banknotesgandhi series banknoteslage raho munna bhailage raho munna bhaisalman khan height, age, girlfriends, family, biography & moresidharth malhotra height, weight, age, girlfriend, family, biography & morealia bhatt age, height, boyfriend, family, biography & morevarun dhawan, height, age, girlfriend, family, facts & moreshraddha kapoor age, height, boyfriend, family, biography & moreshah rukh khan â€“ a detailed biography by starsunfoldedakshay kumar height, age, wife, family, children, biography & moredushyant chautala age, caste, wife, family, biography & morebigg boss 13 voting process (online poll), contestants & eviction detailsnarendra modi age, height, wife, family, caste, biography & moreamitabh bachchan height, age, wife, family, caste, biography & moreekagra dwivedi (child actor) age, family, biography & morefollow us on our social media channels to stay connected.\n",
      "what are the challenges faced by machine learning\n",
      "BRO: machine learning engineers face the opposite.\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"BRO: My name is BRO. I will answer your queries about Computers and AI. If you want to exit, type Bye!\")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye' and user_response != ''):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"BRO: You are welcome..\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"BRO: \"+greeting(user_response))\n",
    "            \n",
    "            else:\n",
    "                print(\"BRO: \",end=\"\")\n",
    "                print(google(user_response))\n",
    "                os.remove(\"data_set1.txt\")\n",
    "                os.remove(\"data_set2.txt\")\n",
    "                os.remove(\"data_set3.txt\")          \n",
    "      \n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"BRO: Bye! take care..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHVn9pKiaemr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Chatbot v2.0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
